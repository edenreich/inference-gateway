---
openapi: 3.1.0
info:
  title: Inference Gateway API
  description: API for interacting with various language models through the Inference Gateway.
  version: 1.0.0
servers:
  - url: http://localhost:8080
paths:
  /llms:
    get:
      summary: List all language models
      responses:
        "200":
          description: A list of models
          content:
            application/json:
              schema:
                type: array
                items:
                  $ref: "#/components/schemas/ProviderModels"
  /llms/{provider}/generate:
    post:
      summary: Generate content with a specific provider's LLM
      parameters:
        - name: provider
          in: path
          required: true
          schema:
            type: string
            enum:
              - ollama
              - groq
              - openai
              - google
              - cloudflare
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                model:
                  type: string
                prompt:
                  type: string
      responses:
        "200":
          description: Generated content
          content:
            application/json:
              schema:
                type: object
                properties:
                  content:
                    type: string
  /llms/{provider}/v1/models:
    get:
      summary: List models of a specific provider
      parameters:
        - name: provider
          in: path
          required: true
          schema:
            type: string
            enum:
              - ollama
              - groq
              - openai
              - google
              - cloudflare
      responses:
        "200":
          description: A list of models
          content:
            application/json:
              schema:
                type: array
                items:
                  type: string
  /llms/{provider}/api/generate:
    post:
      summary: Generate content with a specific provider's LLM
      parameters:
        - name: provider
          in: path
          required: true
          schema:
            type: string
            enum:
              - ollama
              - groq
              - openai
              - google
              - cloudflare
      requestBody:
        required: true
        content:
          application/json:
            schema:
              type: object
              properties:
                model:
                  type: string
                prompt:
                  type: string
      responses:
        "200":
          description: Generated content
          content:
            application/json:
              schema:
                type: object
                properties:
                  content:
                    type: string
  /health:
    get:
      summary: Health check
      responses:
        "200":
          description: Health check successful
components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT
      description: |
        Authentication is available but disabled by default.
        To enable authentication, Set ENABLE_AUTH to true.
  schemas:
    Model:
      type: object
      properties:
        id:
          type: string
        object:
          type: string
        owned_by:
          type: string
        created:
          type: integer
    ProviderModels:
      type: object
      properties:
        provider:
          type: string
          enum:
            - Ollama
            - Groq
            - OpenAI
            - Google
            - Cloudflare
        models:
          type: array
          items:
            type: object
            properties:
              id:
                type: string
              object:
                type: string
              owned_by:
                type: string
              created:
                type: integer
